# AutomaÃ§Ã£o de Processos de RH com Python

## Resumo

Esse projeto Ã© a refatoraÃ§Ã£o de um sistema de alertas inicialmente feito com o power-automate. A ideia Ã© implementar um sistema de monitoramento das automaÃ§Ãµes (fluxo;alertas) com diversas melhorias.
No momento possui uma integraÃ§Ã£o com google sheets onde encaminha as logs de envios para uma planilha dentro do workspace do google.
Trabalhando tambem em uma integracao com streamlit para analises a partir dos dados do google sheets

##  Funcionalidades (Features)

- **Alertas de Horas Extras (para RH):**
  - `DiÃ¡rio:` Envio de alerta individual para o colaborador que excedeu alguma regra (por exemplo, execuÃ§Ã£o total do permitido)
  - `Semanal:` Envio de resumo consolidado para o gestor com a lista do seu time com a regra de limite de execuÃ§Ã£o permitida.
  - `Semanal:` Envio de resumo consolidado para o coordenador com a lista da sua Ã¡rea com a regra de limite de execuÃ§Ã£o permitida.
- **ComunicaÃ§Ãµes de RH:**
  - `DiÃ¡rio:` Envio de e-mail comemorativo no aniversÃ¡rio de empresa de cada funcionÃ¡rio (ex> pessoa entrou dia 15/08/24, se rodar no dia 15/08/25 vai enviar um email de parabens por 1 ano, etc..)  .
  - `DiÃ¡rio:` Envio de lembrete para o gestor sobre o fim do perÃ­odo de experiÃªncia de um colaborador (em desenvolvimento).
- **Monitoramento e Auditoria:**
  - Registro de todas as aÃ§Ãµes em arquivos de log diÃ¡rios e rotacionados.
  - IntegraÃ§Ã£o com Google Sheets para manter um log histÃ³rico de auditoria e dashboards de status diÃ¡rio.
- **Templates Profissionais:**
  - E-mails em HTML com CSS, utilizando um sistema de templates com Jinja2 para garantir consistÃªncia visual e facilidade de manutenÃ§Ã£o.

## Arquitetura do Projeto

O projeto segue uma arquitetura de software profissional baseada no princÃ­pio da SeparaÃ§Ã£o de Responsabilidades para garantir manutenibilidade e escalabilidade.
-- em desenvolvimento

```
AUTOMAÃ‡ÃƒO_RH/
â”‚
â”œâ”€â”€ ğŸ“‚ automations/         # ContÃ©m a lÃ³gica especÃ­fica de cada automaÃ§Ã£o (diÃ¡ria, semanal).
â”œâ”€â”€ ğŸ“‚ config/              # Centraliza todas as configuraÃ§Ãµes da aplicaÃ§Ã£o.
â”œâ”€â”€ ğŸ“‚ core/                # O "motor" reutilizÃ¡vel do projeto.
â”œâ”€â”€ ğŸ“‚ data/                # Arquivos de dados de entrada (ex: contributors.csv).
â”œâ”€â”€ ğŸ“‚ logs/                # Armazena os arquivos de log gerados a cada execuÃ§Ã£o.
â”œâ”€â”€ ğŸ“‚ scripts/             # Orquestradores, os pontos de entrada para executar os fluxos.
â”œâ”€â”€ ğŸ“‚ templates/           # Modelos de e-mail em HTML (Jinja2).
â”œâ”€â”€ .env                    # Arquivo LOCAL com senhas e segredos (ignorado pelo Git).
â””â”€â”€ run_daily_tasks.py      # Exemplo de script orquestrador.
```

### Detalhes da Pasta `core/`
A pasta `core` Ã© o coraÃ§Ã£o da aplicaÃ§Ã£o, contendo toda a lÃ³gica reutilizÃ¡vel:
-   `core/data_loader.py`: ResponsÃ¡vel por carregar, processar e validar os dados brutos da fonte de entrada (ex: arquivo `.csv`).
-   `core/business_rules.py`: ContÃ©m a "inteligÃªncia" e as regras de negÃ³cio centrais. Suas funÃ§Ãµes recebem os dados jÃ¡ carregados e retornam listas de funcionÃ¡rios que atendem a critÃ©rios especÃ­ficos.
-   `core/email_sender.py`: O "operÃ¡rio" de baixo nÃ­vel para e-mails. Sua Ãºnica tarefa Ã© receber uma lista de e-mails jÃ¡ prontos e enviÃ¡-los em paralelo.
-   `core/email_service.py`: A camada de serviÃ§o de alto nÃ­vel para e-mails. Ele orquestra a criaÃ§Ã£o das mensagens, renderizando os templates antes de passar a lista para o `email_sender` enviar.
-   `core/gsheets_client.py`: O "cliente" de baixo nÃ­vel para o Google Sheets. Lida com a autenticaÃ§Ã£o e as operaÃ§Ãµes bÃ¡sicas da API.
-   `core/gsheets_service.py`: A camada de serviÃ§o para a planilha. ContÃ©m funÃ§Ãµes de negÃ³cio como `log_dataframe_to_sheet`.
-   `core/logger_config.py`: Configura o sistema de logging para todo o projeto.
-   `core/utils.py`: Uma "caixa de ferramentas" com funÃ§Ãµes utilitÃ¡rias reutilizÃ¡veis por todo o projeto.

## Como Executar (ainda nao foi revisado)

### PrÃ©-requisitos
- Python 3.10+
- Um ambiente virtual (`.venv`)

### 1. ConfiguraÃ§Ã£o do Ambiente
Clone o repositÃ³rio e instale as dependÃªncias:
```bash
git clone [https://github.com/seu-usuario/automacao_rh.git](https://github.com/seu-usuario/automacao_rh.git)
cd automacao_rh
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o das Credenciais
- **E-mail e App:** Copie o arquivo `.env.example` para um novo arquivo chamado `.env` e preencha com suas credenciais de e-mail (usando uma "Senha de App" do Google).
- **Google Sheets:** Siga o guia para criar uma Conta de ServiÃ§o no Google Cloud, baixe o arquivo de credencial JSON e salve-o na raiz do projeto como `google_credentials.json`. Lembre-se de compartilhar sua planilha com o e-mail da conta de serviÃ§o.

### 3. ExecuÃ§Ã£o
Os scripts principais estÃ£o na pasta `scripts/`. Para executar um fluxo, use:
```bash
# para rodar as tarefas diÃ¡rias
python scripts/run_daily_tasks.py

# para rodar as tarefas semanais
python scripts/run_weekly_tasks.py
```

## ğŸ—ºï¸ Roadmap de Melhorias Futuras

Este projeto serve como uma base robusta para a construÃ§Ã£o de uma pipeline de dados de ponta a ponta, utilizando tecnologias modernas de mercado.

- [ ] **Fase 1: Data Lakehouse e IngestÃ£o**
    - [ ] Migrar a fonte de dados de CSV para tabelas no **Databricks Delta Lake**.
    - [ ] Gerar dados e atualizar diariamente com groq/pandas

- [ ] **Fase 2: TransformaÃ§Ã£o e Qualidade de Dados**
    - [ ] Implementar um projeto **dbt** para modelar e transformar os dados brutos em tabelas analÃ­ticas limpas.
    - [ ] Adicionar testes de qualidade de dados com **`dbt tests`** e validaÃ§Ã£o de schema em Python com **`Pandera`**.

- [ ] **Fase 3: ConteinerizaÃ§Ã£o da AplicaÃ§Ã£o**
    - [ ] Implementar uma suÃ­te de testes unitÃ¡rios com **`pytest`** para a lÃ³gica da aplicaÃ§Ã£o Python.
    - [ ] Empacotar a aplicaÃ§Ã£o completa (automaÃ§Ãµes, core, etc.) em uma imagem **Docker**.

- [ ] **Fase 4: OrquestraÃ§Ã£o e CI/CD**
    - [ ] Configurar **GitHub Actions** para automaÃ§Ã£o de testes (CI) e build da imagem Docker (CD).
    - [ ] Desenvolver uma DAG no **Apache Airflow** para orquestrar a execuÃ§Ã£o do `dbt` e do container Docker da aplicaÃ§Ã£o.

- [ ] **Fase 5: VisualizaÃ§Ã£o e AÃ§Ã£o**
    - [ ] Criar um dashboard interativo com **Streamlit** conectado diretamente ao Databricks para visualizaÃ§Ã£o de KPIs.
    - [ ] Manter e expandir o sistema de notificaÃ§Ãµes por e-mail como a camada de "aÃ§Ã£o" da pipeline.
     


## Responsaveis

Eduardo Lima  
Victor Castro
